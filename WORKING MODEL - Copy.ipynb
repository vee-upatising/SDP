{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     A B A B B B A Z 0 0\n",
       "1     A C A C C C A Z 0 0\n",
       "2     A D A D D D A Z 0 0\n",
       "3     C B C B C B C B Z 0\n",
       "4     A A A B A A A B Z 0\n",
       "5     C C C B C C C B Z 0\n",
       "6     A B C A B C A Z 0 0\n",
       "7     D B D B B B D Z 0 0\n",
       "8     D B A D B D A Z 0 0\n",
       "9     C A D B D A B D Z 0\n",
       "10    D G A D G D A D Z 0\n",
       "11    E E E F E E F Z 0 0\n",
       "12    F A G F A G Z 0 0 0\n",
       "13    E B A G B A G Z 0 0\n",
       "14    B B B B B B B B Z 0\n",
       "15    A G B E A A G B E Z\n",
       "16    E B G E B G E B B Z\n",
       "17    F F F F F F F F Z 0\n",
       "18    A F E F A F E F Z 0\n",
       "19    B F E G B F E G Z 0\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = pd.read_csv('data.csv', header = None)\n",
    "data = csv.iloc[:, 0]\n",
    "target = csv.iloc[:, 1]\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_lexicon = \" \".join(target).split()\n",
    "def create_lookup_tables(words):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    :param words: Input list of words\n",
    "    :return: A tuple of dicts.  The first dict maps a vocab word to and integeter\n",
    "             The second maps an integer back to to the vocab word\n",
    "    \"\"\"\n",
    "    word_counts = Counter(words)\n",
    "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab, 1)}\n",
    "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
    "\n",
    "    return vocab_to_int, int_to_vocab\n",
    "vocab_to_int, int_to_vocab = create_lookup_tables(full_lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for x in range(len(data)):\n",
    "    d.append(data[x].split(\" \"))\n",
    "for x in range(len(d)):\n",
    "    for z in range(len(d[x])):\n",
    "        if d[x][z] == 'A':\n",
    "            d[x][z] = vocab_to_int['A']\n",
    "        elif d[x][z] == 'B':\n",
    "            d[x][z] = vocab_to_int['B']\n",
    "        elif d[x][z] == 'C':\n",
    "            d[x][z] = vocab_to_int['C']\n",
    "        elif d[x][z] == 'D':\n",
    "            d[x][z] = vocab_to_int['D']\n",
    "        elif d[x][z] == 'E':\n",
    "            d[x][z] = vocab_to_int['E']\n",
    "        elif d[x][z] == 'F':\n",
    "            d[x][z] = vocab_to_int['F']\n",
    "        elif d[x][z] == 'G':\n",
    "            d[x][z] = vocab_to_int['G']\n",
    "        elif d[x][z] == 'Z':\n",
    "            d[x][z] = vocab_to_int['Z']\n",
    "d = [d]\n",
    "d = np.array(d)\n",
    "d = d.reshape(20, 1, 5) / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for x in range(len(target)):\n",
    "    a.append(target[x].split(\" \"))\n",
    "for x in range(len(a)):\n",
    "    for z in range(len(a[x])):\n",
    "        if a[x][z] == 'A':\n",
    "            a[x][z] = int(vocab_to_int['A'])\n",
    "        elif a[x][z] == 'B':\n",
    "            a[x][z] = vocab_to_int['B']\n",
    "        elif a[x][z] == 'C':\n",
    "            a[x][z] = vocab_to_int['C']\n",
    "        elif a[x][z] == 'D':\n",
    "            a[x][z] = vocab_to_int['D']\n",
    "        elif a[x][z] == 'E':\n",
    "            a[x][z] = vocab_to_int['E']\n",
    "        elif a[x][z] == 'F':\n",
    "            a[x][z] = vocab_to_int['F']\n",
    "        elif a[x][z] == 'G':\n",
    "            a[x][z] = vocab_to_int['G']\n",
    "        elif a[x][z] == 'Z':\n",
    "            a[x][z] = vocab_to_int['Z']\n",
    "        elif a[x][z] == '0':\n",
    "            a[x][z] = 0\n",
    "\n",
    "a = [a]\n",
    "a = np.array(a)\n",
    "a = a.reshape(20, 1, 10) / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2., 1., 2., 1., 4.]],\n",
       "\n",
       "       [[2., 6., 2., 6., 4.]],\n",
       "\n",
       "       [[2., 7., 2., 7., 4.]],\n",
       "\n",
       "       [[6., 1., 6., 1., 4.]],\n",
       "\n",
       "       [[2., 2., 2., 1., 4.]],\n",
       "\n",
       "       [[6., 6., 6., 1., 4.]],\n",
       "\n",
       "       [[2., 1., 6., 2., 4.]],\n",
       "\n",
       "       [[7., 1., 7., 1., 4.]],\n",
       "\n",
       "       [[7., 1., 2., 7., 4.]],\n",
       "\n",
       "       [[6., 2., 7., 1., 4.]],\n",
       "\n",
       "       [[7., 9., 2., 7., 4.]],\n",
       "\n",
       "       [[8., 8., 8., 5., 4.]],\n",
       "\n",
       "       [[5., 5., 2., 9., 4.]],\n",
       "\n",
       "       [[8., 1., 2., 9., 4.]],\n",
       "\n",
       "       [[1., 1., 1., 1., 4.]],\n",
       "\n",
       "       [[2., 9., 1., 8., 4.]],\n",
       "\n",
       "       [[8., 9., 1., 1., 4.]],\n",
       "\n",
       "       [[5., 5., 5., 5., 4.]],\n",
       "\n",
       "       [[2., 5., 8., 5., 4.]],\n",
       "\n",
       "       [[1., 5., 8., 9., 4.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2., 1., 2., 1., 1., 1., 2., 4., 0., 0.]],\n",
       "\n",
       "       [[2., 6., 2., 6., 6., 6., 2., 4., 0., 0.]],\n",
       "\n",
       "       [[2., 7., 2., 7., 7., 7., 2., 4., 0., 0.]],\n",
       "\n",
       "       [[6., 1., 6., 1., 6., 1., 6., 1., 4., 0.]],\n",
       "\n",
       "       [[2., 2., 2., 1., 2., 2., 2., 1., 4., 0.]],\n",
       "\n",
       "       [[6., 6., 6., 1., 6., 6., 6., 1., 4., 0.]],\n",
       "\n",
       "       [[2., 1., 6., 2., 1., 6., 2., 4., 0., 0.]],\n",
       "\n",
       "       [[7., 1., 7., 1., 1., 1., 7., 4., 0., 0.]],\n",
       "\n",
       "       [[7., 1., 2., 7., 1., 7., 2., 4., 0., 0.]],\n",
       "\n",
       "       [[6., 2., 7., 1., 7., 2., 1., 7., 4., 0.]],\n",
       "\n",
       "       [[7., 9., 2., 7., 9., 7., 2., 7., 4., 0.]],\n",
       "\n",
       "       [[8., 8., 8., 5., 8., 8., 5., 4., 0., 0.]],\n",
       "\n",
       "       [[5., 2., 9., 5., 2., 9., 4., 0., 0., 0.]],\n",
       "\n",
       "       [[8., 1., 2., 9., 1., 2., 9., 4., 0., 0.]],\n",
       "\n",
       "       [[1., 1., 1., 1., 1., 1., 1., 1., 4., 0.]],\n",
       "\n",
       "       [[2., 9., 1., 8., 2., 2., 9., 1., 8., 4.]],\n",
       "\n",
       "       [[8., 1., 9., 8., 1., 9., 8., 1., 1., 4.]],\n",
       "\n",
       "       [[5., 5., 5., 5., 5., 5., 5., 5., 4., 0.]],\n",
       "\n",
       "       [[2., 5., 8., 5., 2., 5., 8., 5., 4., 0.]],\n",
       "\n",
       "       [[1., 5., 8., 9., 1., 5., 8., 9., 4., 0.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data into train and test sets. 3/4 train, 1/4 test.\n",
    "x_train,x_test,y_train,y_test = train_test_split(d, a, test_size=0.2, shuffle=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0913 15:46:16.185493  7644 deprecation_wrapper.py:119] From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0913 15:46:16.196464  7644 deprecation_wrapper.py:119] From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0913 15:46:16.198480  7644 deprecation_wrapper.py:119] From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0913 15:46:16.801033  7644 deprecation_wrapper.py:119] From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0913 15:46:16.805023  7644 deprecation.py:506] From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0913 15:46:18.645099  7644 deprecation_wrapper.py:119] From D:\\Anaconda\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 1, 128)            68608     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 1, 128)            131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 128)            16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1, 128)            16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1, 128)            16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1, 10)             1290      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1, 10)             110       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1, 10)             110       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1, 10)             0         \n",
      "=================================================================\n",
      "Total params: 2,488,166\n",
      "Trainable params: 2,488,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#getting the right tensor shape for this was a BITCH\n",
    "model = Sequential()  \n",
    "model.add(LSTM(128, input_shape=(1, 5),return_sequences=True, activation = 'relu'))\n",
    "model.add(LSTM(128, return_sequences=True, activation = 'relu'))\n",
    "model.add(LSTM(128, return_sequences=True, activation = 'relu'))\n",
    "model.add(LSTM(128, return_sequences=True, activation = 'relu'))\n",
    "model.add(LSTM(128, return_sequences=True, activation = 'tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, return_sequences=True, activation = 'relu'))\n",
    "model.add(LSTM(128, return_sequences=True, activation = 'relu'))\n",
    "model.add(LSTM(128, return_sequences=True, activation = 'relu'))\n",
    "model.add(LSTM(128, return_sequences=True, activation = 'relu'))\n",
    "model.add(LSTM(128, return_sequences=True, activation = 'relu'))\n",
    "model.add(LSTM(128, return_sequences=True, activation = 'sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128, return_sequences=True, activation = 'relu'))\n",
    "model.add(LSTM(128, return_sequences=True, activation = 'relu'))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(128, return_sequences=True, activation = 'relu'))\n",
    "model.add(LSTM(128, return_sequences=True, activation = 'relu'))\n",
    "model.add(LSTM(128, return_sequences=True, activation = 'tanh'))\n",
    "model.add(LSTM(128, return_sequences=True, activation = 'relu'))\n",
    "model.add(LSTM(128, return_sequences=True, activation = 'relu'))\n",
    "model.add(Dense(units=128))\n",
    "model.add(Dense(units=128))\n",
    "model.add(Dense(units=128))\n",
    "model.add(Dense(units=10))\n",
    "model.add(Dense(units=10))\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0913 15:46:19.051013  7644 deprecation.py:323] From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0913 15:46:25.749111  7644 deprecation_wrapper.py:119] From D:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20 samples, validate on 4 samples\n",
      "Epoch 1/25\n",
      " - 9s - loss: 0.3793 - val_loss: 0.4994\n",
      "Epoch 2/25\n",
      " - 0s - loss: 0.3731 - val_loss: 0.4947\n",
      "Epoch 3/25\n",
      " - 0s - loss: 0.3666 - val_loss: 0.4902\n",
      "Epoch 4/25\n",
      " - 0s - loss: 0.3610 - val_loss: 0.4883\n",
      "Epoch 5/25\n",
      " - 0s - loss: 0.3594 - val_loss: 0.4879\n",
      "Epoch 6/25\n",
      " - 0s - loss: 0.3587 - val_loss: 0.4887\n",
      "Epoch 7/25\n",
      " - 0s - loss: 0.3580 - val_loss: 0.4887\n",
      "Epoch 8/25\n",
      " - 0s - loss: 0.3569 - val_loss: 0.4886\n",
      "Epoch 9/25\n",
      " - 0s - loss: 0.3563 - val_loss: 0.4879\n",
      "Epoch 10/25\n",
      " - 0s - loss: 0.3561 - val_loss: 0.4877\n",
      "Epoch 11/25\n",
      " - 0s - loss: 0.3560 - val_loss: 0.4876\n",
      "Epoch 12/25\n",
      " - 0s - loss: 0.3557 - val_loss: 0.4879\n",
      "Epoch 13/25\n",
      " - 0s - loss: 0.3555 - val_loss: 0.4883\n",
      "Epoch 14/25\n",
      " - 0s - loss: 0.3555 - val_loss: 0.4877\n",
      "Epoch 15/25\n",
      " - 0s - loss: 0.3554 - val_loss: 0.4876\n",
      "Epoch 16/25\n",
      " - 0s - loss: 0.3554 - val_loss: 0.4879\n",
      "Epoch 17/25\n",
      " - 0s - loss: 0.3556 - val_loss: 0.4896\n",
      "Epoch 18/25\n",
      " - 0s - loss: 0.3560 - val_loss: 0.4882\n",
      "Epoch 19/25\n",
      " - 0s - loss: 0.3567 - val_loss: 0.4885\n",
      "Epoch 20/25\n",
      " - 0s - loss: 0.3559 - val_loss: 0.4889\n",
      "Epoch 21/25\n",
      " - 0s - loss: 0.3560 - val_loss: 0.4889\n",
      "Epoch 22/25\n",
      " - 0s - loss: 0.3557 - val_loss: 0.4886\n",
      "Epoch 23/25\n",
      " - 0s - loss: 0.3555 - val_loss: 0.4881\n",
      "Epoch 24/25\n",
      " - 0s - loss: 0.3557 - val_loss: 0.4879\n",
      "Epoch 25/25\n",
      " - 0s - loss: 0.3555 - val_loss: 0.4876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b19ffd6748>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(d, a, epochs=25, batch_size=5, verbose=2,validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = np.array([2, 1, 1, 1, 4])\n",
    "guess = guess.reshape(1,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_on_batch(guess)*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "array = np.around(predict[0][0])\n",
    "print(array)\n",
    "new = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for z in range(len(array)):\n",
    "    if array[z] == 1:\n",
    "        new.append(int_to_vocab[1])\n",
    "    elif array[z] == 2:\n",
    "        new.append(int_to_vocab[2])\n",
    "    elif array[z] == 3:\n",
    "        new.append(int_to_vocab[3])\n",
    "    elif array[z] == 4:\n",
    "        new.append(int_to_vocab[4])\n",
    "    elif array[z] == 5:\n",
    "        new.append(int_to_vocab[5])\n",
    "    elif array[z] == 6:\n",
    "        new.append(int_to_vocab[6])\n",
    "    elif array[z] == 7:\n",
    "        new.append(int_to_vocab[7])\n",
    "    elif array[z] == 8:\n",
    "        new.append(int_to_vocab[8])\n",
    "    elif array[z] == 0:\n",
    "        new.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 0, 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
